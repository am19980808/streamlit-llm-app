import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# =========================
# LLMã«è³ªå•ã™ã‚‹é–¢æ•°
# =========================
def ask_llm(user_input: str, expert_type: str) -> str:
    if expert_type == "å¥åº·ã®å°‚é–€å®¶":
        system_message = """
ã‚ãªãŸã¯å¥åº·ãƒ»åŒ»ç™‚ãƒ»ç”Ÿæ´»ç¿’æ…£ã«è©³ã—ã„å°‚é–€å®¶ã§ã™ã€‚
åˆå¿ƒè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãã€å®Ÿç”Ÿæ´»ã«å½¹ç«‹ã¤ã‚ˆã†ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
åŒ»ç™‚è¡Œç‚ºã®æ–­å®šã¯é¿ã‘ã€ä¸€èˆ¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã«ç•™ã‚ã¦ãã ã•ã„ã€‚
"""
    elif expert_type == "è¦³å…‰ã®å°‚é–€å®¶":
        system_message = """
ã‚ãªãŸã¯æ—…è¡Œãƒ»è¦³å…‰ã®å°‚é–€å®¶ã§ã™ã€‚
è¦³å…‰åœ°ã®é­…åŠ›ã‚„æ¥½ã—ã¿æ–¹ã€æ³¨æ„ç‚¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
åˆå¿ƒè€…ã«ã‚‚å„ªã—ã„è¡¨ç¾ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
"""
    else:
        system_message = "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "{input}")
    ])

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7
    )

    chain = prompt | llm
    result = chain.invoke({"input": user_input})

    return result.content


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="å°‚é–€å®¶AIç›¸è«‡ã‚¢ãƒ—ãƒª", layout="centered")

st.title("ğŸ§  å°‚é–€å®¶AIç›¸è«‡ã‚¢ãƒ—ãƒª")
st.write("""
å…¥åŠ›ã—ãŸå†…å®¹ã«å¯¾ã—ã¦ã€é¸æŠã—ãŸå°‚é–€å®¶ã¨ã—ã¦AIãŒå›ç­”ã—ã¾ã™ã€‚
""")

expert_type = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„",
    ["å¥åº·ã®å°‚é–€å®¶", "è¦³å…‰ã®å°‚é–€å®¶"]
)

user_input = st.text_area(
    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
    placeholder="ä¾‹ï¼šå¥åº·çš„ãªç”Ÿæ´»ç¿’æ…£ã‚’æ•™ãˆã¦ / äº¬éƒ½æ—…è¡Œã®ãŠã™ã™ã‚ã¯ï¼Ÿ"
)

if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
            answer = ask_llm(user_input, expert_type)

        st.subheader("ğŸ’¡ AIã®å›ç­”")
        st.write(answer)
